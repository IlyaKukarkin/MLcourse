{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature = None, threshold = None, left_child = None, right_child = None, *, value = None):\n",
    "        #feature - критерий разбиения\n",
    "        #threshold - порог разбиения \n",
    "        #left child - нода слева\n",
    "        #right child - нода справа \n",
    "        #value - значение ноды, если она коненчая \n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child\n",
    "        self.value = value\n",
    "    def is_leaf_node(self):\n",
    "        #Проверить является ли нода конечным листом\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, min_rows_split=2, max_depth=10, number_of_features=None):\n",
    "        #min_rows_split - минимальнок количетво записей неоюходимых для разбиения \n",
    "        #max_depth - максимальная глубина дерева \n",
    "        #number_of_features - подмножество критериев для разбиения\n",
    "        #root - ссылка на корень дерева\n",
    "        self.min_rows_split = min_rows_split\n",
    "        self.max_depth = max_depth\n",
    "        self.number_of_features = number_of_features\n",
    "        self.root = None\n",
    "    def _create_tree(self, X, y, depth=0):\n",
    "        #Количетсво строк и столбцов\n",
    "        rows, features = X.shape\n",
    "        #Уникальные проедсказываемые значения y\n",
    "        labels = len(np.unique(y))\n",
    "        #Проверка критериев остановки\n",
    "        if(depth >= self.max_depth or labels == 1 or rows <self.min_rows_split):\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value = leaf_value)\n",
    "        #Случайный набор\n",
    "        feature_indexes = np.random.choice(features, self.number_of_features, replace = False)\n",
    "        #Найти в этом наборе лучшее свойство для разбиения и лучший порог разбиения\n",
    "        best_feature, best_threshold = self._best_criteria(X, y, feature_indexes)\n",
    "        #Разделить\n",
    "        left_indexes, right_indexes = self._split(X[:, best_feature], best_threshold)\n",
    "        #Создать ноду слева рекурсивно\n",
    "        left_child = self._create_tree(X[left_indexes, :], y[left_indexes], depth+1)\n",
    "        #Создать ноду справа\n",
    "        right_child = self._create_tree(X[right_indexes, :], y[right_indexes], depth+1)\n",
    "        return Node(best_feature, best_threshold, left_child, right_child)\n",
    "    def _best_criteria(self, X, y, feature_indexes):\n",
    "        #Information gain\n",
    "        best_gain = -1\n",
    "        #Свойство и порог дл разбиения \n",
    "        split_index, split_threshold = None, None\n",
    "        #Для каждого свойства\n",
    "        for feature_index in feature_indexes:\n",
    "            X_column = X[:, feature_index]\n",
    "            thresholds = np.unique(X_column)\n",
    "            #Для кажого порога \n",
    "            for threshold in thresholds:\n",
    "                #Подсчитать ig\n",
    "                gain = self._count_information_gain(y, X_column, threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_index = feature_index\n",
    "                    split_threshold = threshold\n",
    "        return split_index, split_threshold\n",
    "    def _count_information_gain(self, y, X_column, threshold):\n",
    "        parent_entropy = self._count_entropy(y)\n",
    "        left_indexes, right_indexes = self._split(X_column, threshold)\n",
    "        if len(left_indexes) == 0 or len(right_indexes) == 0:\n",
    "            return 0\n",
    "\n",
    "        n = len(y)\n",
    "        left_len, right_len = len(left_indexes), len(right_indexes)\n",
    "        entropy_left, entropy_right = self._count_entropy(y[left_indexes]), self._count_entropy(y[right_indexes])\n",
    "        #Энтропия для упорядоченого множества\n",
    "        child_entropy = (left_len / n) * entropy_left + (right_len / n) * entropy_right\n",
    "\n",
    "        # Подсчиать ig\n",
    "        ig = parent_entropy - child_entropy\n",
    "        return ig\n",
    "    def _split(self, X_column, threshold):\n",
    "        left_indexes = np.argwhere(X_column <= threshold).flatten()\n",
    "        right_indexes = np.argwhere(X_column > threshold).flatten()\n",
    "        return left_indexes, right_indexes\n",
    "    def _traverse_tree(self, x, node):\n",
    "        #Проход по дереву\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left_child)\n",
    "        return self._traverse_tree(x, node.right_child)\n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        return counter.most_common(1)[0][0]\n",
    "    def _count_entropy(self, y):\n",
    "        #Общее количество записей\n",
    "        n = len(y)\n",
    "        #Количетво вхождений неотрицательных значений\n",
    "        hist = np.bincount(y)\n",
    "        #Вероятности \n",
    "        probabilities = hist / n\n",
    "        #Энтропия Шенона\n",
    "        return -np.sum([pi * np.log2(pi) for pi in probabilities if pi > 0])\n",
    "    def trainDecisionTree(self, X, y):\n",
    "        self.number_of_features = X.shape[1] if not self.number_of_features else min(self.number_of_features, X.shape[1])\n",
    "        #Начать построение дерева с корня\n",
    "        self.root = self._create_tree(X, y)\n",
    "    def predictDecisionTree(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "    def score(self, y_test, y_pred):\n",
    "        score = np.sum(y_test == y_pred) / len(y_test)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_trees=8, min_rows_split=2,\n",
    "                 max_depth=100, number_of_features=None):\n",
    "        #Количество деревьев в лесу\n",
    "        self.n_trees = n_trees\n",
    "        self.min_rows_split = min_rows_split\n",
    "        self.max_depth = max_depth\n",
    "        self.number_of_features = number_of_features\n",
    "        #Сами деревья\n",
    "        self.trees = []\n",
    "\n",
    "    def trainRandomForest(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            #Создать дерево\n",
    "            tree = DecisionTreeClassifier(min_rows_split=self.min_rows_split,\n",
    "                max_depth=self.max_depth, number_of_features=self.number_of_features)\n",
    "            #Разбить выборку\n",
    "            X_train, y_train = self._random_split(X, y)\n",
    "            #Построить дерево\n",
    "            tree.trainDecisionTree(X_train, y_train)\n",
    "            #Добавить в список деревьев\n",
    "            self.trees.append(tree)\n",
    "    def predictRandomForest(self, X):\n",
    "        #Список предсказаний\n",
    "        tree_preds = np.array([tree.predictDecisionTree(X) for tree in self.trees])\n",
    "        tree_preds = np.swapaxes(tree_preds, 0, 1)\n",
    "        prediction = [self._most_common_label(tree_pred) for tree_pred in tree_preds]\n",
    "        return np.array(prediction)\n",
    "    def _random_split(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        idxs = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        return X[idxs], y[idxs]\n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        return most_common\n",
    "    def score(self, y_pred, y_test):\n",
    "        score = np.sum(y_test == y_pred) / len(y_test)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "class GradientBoosting():\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, tol=0.5):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tol = tol\n",
    "        # Основной оценщик\n",
    "        self.base_estimator = DecisionTreeRegressor(max_depth=10)\n",
    "\n",
    "    def trainGradientBoosting(self, X, y):\n",
    "        dtg = DecisionTreeRegressor(max_depth=10)\n",
    "        self._estimators = [dtg]\n",
    "        f = dtg.fit(X, y)\n",
    "        # Начать последовательное построение дерева\n",
    "        for m in range(self.n_estimators):\n",
    "            # предсказать, используя все модели, обученных до этой эпохи\n",
    "            f = self._predict(X)\n",
    "            # рассчитать остатки от предыдущего шага\n",
    "            residuals = self._logistic_gradient(y, f)\n",
    "            # новая модель g для псевдо-остатков\n",
    "            model = self._estimators[m].fit(X, residuals)\n",
    "            # Добавить модель к оценщикам, чтобы использовать в прогнозе в след итерации\n",
    "            self._estimators.append(model)\n",
    "        return self\n",
    "\n",
    "    def _predict(self, X):\n",
    "        # Базовая оценка\n",
    "        f_0 = self._estimators[0].predict(X)\n",
    "        # Прогнозы скорректированные на скорость обучения\n",
    "        boosting = np.sum([self.learning_rate * f.predict(X) for f in self._estimators[1:]], axis=0)\n",
    "        return f_0 + boosting\n",
    "\n",
    "    def _logistic_gradient(self, y, f):\n",
    "        return y - expit(f)\n",
    "\n",
    "    def _proba_to_class(self, sample):\n",
    "        return int(sample > self.tol)\n",
    "\n",
    "    def predictGradientBoosting(self, X):\n",
    "        # Прерватить значения в веротяности 0/1\n",
    "        predicted_probas = expit(self._predict(X))\n",
    "        # Сложить их в массив\n",
    "        return np.array([self._proba_to_class(sample) for sample in predicted_probas])\n",
    "\n",
    "    def score(self, y_pred, y_test):\n",
    "        score = np.sum(y_test == y_pred) / len(y_test)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Импорт данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('test.csv', sep=',')\n",
    "y = data['Visited'].to_numpy()\n",
    "X = data.drop(columns=['Visited']).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разбиение выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание для дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 1 0 0]\n",
      "0.7232954545454545\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10)\n",
    "tree.trainDecisionTree(X_train, y_train)\n",
    "    \n",
    "y_pred = tree.predictDecisionTree(X_test)\n",
    "print(y_pred)\n",
    "print(tree.score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание для случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 1 0]\n",
      "0.7022727272727273\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForest(n_trees = 5)\n",
    "forest.trainRandomForest(X_train, y_train)\n",
    "y_pred = forest.predictRandomForest(X_test)\n",
    "print(y_pred)\n",
    "print(forest.score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание для градиентного бустинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 0 1 0]\n",
      "0.5772727272727273\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoosting()\n",
    "gb.trainGradientBoosting(X_train, y_train)\n",
    "y_pred = gb.predictGradientBoosting(X_test)\n",
    "print(y_pred)\n",
    "print(gb.score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
